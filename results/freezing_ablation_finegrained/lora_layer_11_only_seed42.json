{
  "config_name": "lora_layer_11_only",
  "description": "LoRA applied ONLY to layer 11 (query+value), ~99.9% frozen",
  "seed": 42,
  "frozen_percentage": 99.98,
  "trainable_params": 26114,
  "total_params": 109509892,
  "accuracy_matrix": {
    "rte": {
      "after_rte": 0.555956678700361,
      "after_mrpc": 0.4729241877256318,
      "after_cola": 0.4693140794223827,
      "after_sst2": 0.4729241877256318
    },
    "mrpc": {
      "after_mrpc": 0.6838235294117647,
      "after_cola": 0.6862745098039216,
      "after_sst2": 0.6838235294117647
    },
    "cola": {
      "after_cola": 0.6912751677852349,
      "after_sst2": 0.6912751677852349
    },
    "sst2": {
      "after_sst2": 0.5091743119266054
    }
  },
  "avg_forgetting": 0.0277,
  "max_forgetting": 0.083,
  "forgetting_per_task": {
    "rte": 0.083,
    "mrpc": 0.0,
    "cola": 0.0
  },
  "time_hours": 0.1384
}
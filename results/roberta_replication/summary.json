{
  "experiment": "RoBERTa-base Replication",
  "model": "roberta-base",
  "total_time_hours": 1.09,
  "total_experiments": 6,
  "successful": 6,
  "method_summary": {
    "full": {
      "avg_forgetting_mean": 0.2424,
      "avg_forgetting_std": 0.0215,
      "final_accuracy_mean": 0.6484,
      "final_accuracy_std": 0.0141,
      "n_seeds": 3
    },
    "lora": {
      "avg_forgetting_mean": 0.0174,
      "avg_forgetting_std": 0.0102,
      "final_accuracy_mean": 0.5932,
      "final_accuracy_std": 0.002,
      "n_seeds": 3
    }
  },
  "results": {
    "full_seed42": {
      "model": "roberta-base",
      "method": "full",
      "seed": 42,
      "timestamp": "2026-03-01T18:51:31.810338",
      "task_sequence": [
        "rte",
        "mrpc",
        "cola",
        "sst2"
      ],
      "accuracy_matrix": {
        "rte": {
          "after_rte": 0.7256317689530686,
          "after_mrpc": 0.5126353790613718,
          "after_cola": 0.4584837545126354,
          "after_sst2": 0.3971119133574007
        },
        "mrpc": {
          "after_mrpc": 0.8725490196078431,
          "after_cola": 0.6862745098039216,
          "after_sst2": 0.6421568627450981
        },
        "cola": {
          "after_cola": 0.825503355704698,
          "after_sst2": 0.5666347075743049
        },
        "sst2": {
          "after_sst2": 0.911697247706422
        }
      },
      "forgetting_metrics": {
        "avg_forgetting": 0.2726,
        "max_forgetting": 0.3285,
        "forgetting_per_task": {
          "rte": 0.3285,
          "mrpc": 0.2304,
          "cola": 0.2589
        },
        "final_avg_accuracy": 0.6294,
        "initial_avg_accuracy": 0.8338
      },
      "time_hours": 0.1248
    },
    "full_seed43": {
      "model": "roberta-base",
      "method": "full",
      "seed": 43,
      "timestamp": "2026-03-01T19:08:09.406204",
      "task_sequence": [
        "rte",
        "mrpc",
        "cola",
        "sst2"
      ],
      "accuracy_matrix": {
        "rte": {
          "after_rte": 0.7292418772563177,
          "after_mrpc": 0.5054151624548736,
          "after_cola": 0.4693140794223827,
          "after_sst2": 0.47653429602888087
        },
        "mrpc": {
          "after_mrpc": 0.8774509803921569,
          "after_cola": 0.6862745098039216,
          "after_sst2": 0.6568627450980392
        },
        "cola": {
          "after_cola": 0.8216682646212847,
          "after_sst2": 0.6212847555129435
        },
        "sst2": {
          "after_sst2": 0.8979357798165137
        }
      },
      "forgetting_metrics": {
        "avg_forgetting": 0.2246,
        "max_forgetting": 0.2527,
        "forgetting_per_task": {
          "rte": 0.2527,
          "mrpc": 0.2206,
          "cola": 0.2004
        },
        "final_avg_accuracy": 0.6632,
        "initial_avg_accuracy": 0.8316
      },
      "time_hours": 0.2771
    },
    "full_seed44": {
      "model": "roberta-base",
      "method": "full",
      "seed": 44,
      "timestamp": "2026-03-01T19:28:51.507639",
      "task_sequence": [
        "rte",
        "mrpc",
        "cola",
        "sst2"
      ],
      "accuracy_matrix": {
        "rte": {
          "after_rte": 0.7328519855595668,
          "after_mrpc": 0.49458483754512633,
          "after_cola": 0.4729241877256318,
          "after_sst2": 0.44404332129963897
        },
        "mrpc": {
          "after_mrpc": 0.8504901960784313,
          "after_cola": 0.6862745098039216,
          "after_sst2": 0.6862745098039216
        },
        "cola": {
          "after_cola": 0.8274209012464045,
          "after_sst2": 0.5906040268456376
        },
        "sst2": {
          "after_sst2": 0.8899082568807339
        }
      },
      "forgetting_metrics": {
        "avg_forgetting": 0.2299,
        "max_forgetting": 0.2888,
        "forgetting_per_task": {
          "rte": 0.2888,
          "mrpc": 0.1642,
          "cola": 0.2368
        },
        "final_avg_accuracy": 0.6527,
        "initial_avg_accuracy": 0.8252
      },
      "time_hours": 0.3446
    },
    "lora_seed42": {
      "model": "roberta-base",
      "method": "lora",
      "seed": 42,
      "timestamp": "2026-03-01T19:36:17.106414",
      "task_sequence": [
        "rte",
        "mrpc",
        "cola",
        "sst2"
      ],
      "accuracy_matrix": {
        "rte": {
          "after_rte": 0.49097472924187724,
          "after_mrpc": 0.4729241877256318,
          "after_cola": 0.4729241877256318,
          "after_sst2": 0.4729241877256318
        },
        "mrpc": {
          "after_mrpc": 0.6838235294117647,
          "after_cola": 0.6838235294117647,
          "after_sst2": 0.6838235294117647
        },
        "cola": {
          "after_cola": 0.6941514860977949,
          "after_sst2": 0.7018216682646213
        },
        "sst2": {
          "after_sst2": 0.5206422018348624
        }
      },
      "forgetting_metrics": {
        "avg_forgetting": 0.0035,
        "max_forgetting": 0.0181,
        "forgetting_per_task": {
          "rte": 0.0181,
          "mrpc": 0.0,
          "cola": -0.0077
        },
        "final_avg_accuracy": 0.5948,
        "initial_avg_accuracy": 0.5974
      },
      "time_hours": 0.1233
    },
    "lora_seed43": {
      "model": "roberta-base",
      "method": "lora",
      "seed": 43,
      "timestamp": "2026-03-01T19:43:03.330508",
      "task_sequence": [
        "rte",
        "mrpc",
        "cola",
        "sst2"
      ],
      "accuracy_matrix": {
        "rte": {
          "after_rte": 0.5631768953068592,
          "after_mrpc": 0.4729241877256318,
          "after_cola": 0.4729241877256318,
          "after_sst2": 0.4729241877256318
        },
        "mrpc": {
          "after_mrpc": 0.6838235294117647,
          "after_cola": 0.6838235294117647,
          "after_sst2": 0.6838235294117647
        },
        "cola": {
          "after_cola": 0.6912751677852349,
          "after_sst2": 0.697986577181208
        },
        "sst2": {
          "after_sst2": 0.5229357798165137
        }
      },
      "forgetting_metrics": {
        "avg_forgetting": 0.0278,
        "max_forgetting": 0.0903,
        "forgetting_per_task": {
          "rte": 0.0903,
          "mrpc": 0.0,
          "cola": -0.0067
        },
        "final_avg_accuracy": 0.5944,
        "initial_avg_accuracy": 0.6153
      },
      "time_hours": 0.1128
    },
    "lora_seed44": {
      "model": "roberta-base",
      "method": "lora",
      "seed": 44,
      "timestamp": "2026-03-01T19:49:38.107112",
      "task_sequence": [
        "rte",
        "mrpc",
        "cola",
        "sst2"
      ],
      "accuracy_matrix": {
        "rte": {
          "after_rte": 0.5379061371841155,
          "after_mrpc": 0.4729241877256318,
          "after_cola": 0.4729241877256318,
          "after_sst2": 0.4729241877256318
        },
        "mrpc": {
          "after_mrpc": 0.6838235294117647,
          "after_cola": 0.6838235294117647,
          "after_sst2": 0.6838235294117647
        },
        "cola": {
          "after_cola": 0.6912751677852349,
          "after_sst2": 0.6931927133269415
        },
        "sst2": {
          "after_sst2": 0.5114678899082569
        }
      },
      "forgetting_metrics": {
        "avg_forgetting": 0.021,
        "max_forgetting": 0.065,
        "forgetting_per_task": {
          "rte": 0.065,
          "mrpc": 0.0,
          "cola": -0.0019
        },
        "final_avg_accuracy": 0.5904,
        "initial_avg_accuracy": 0.6061
      },
      "time_hours": 0.1096
    }
  }
}
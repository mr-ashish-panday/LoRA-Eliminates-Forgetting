{
  "model": "roberta-base",
  "method": "lora",
  "seed": 42,
  "timestamp": "2026-03-01T19:36:17.106414",
  "task_sequence": [
    "rte",
    "mrpc",
    "cola",
    "sst2"
  ],
  "accuracy_matrix": {
    "rte": {
      "after_rte": 0.49097472924187724,
      "after_mrpc": 0.4729241877256318,
      "after_cola": 0.4729241877256318,
      "after_sst2": 0.4729241877256318
    },
    "mrpc": {
      "after_mrpc": 0.6838235294117647,
      "after_cola": 0.6838235294117647,
      "after_sst2": 0.6838235294117647
    },
    "cola": {
      "after_cola": 0.6941514860977949,
      "after_sst2": 0.7018216682646213
    },
    "sst2": {
      "after_sst2": 0.5206422018348624
    }
  },
  "forgetting_metrics": {
    "avg_forgetting": 0.0035,
    "max_forgetting": 0.0181,
    "forgetting_per_task": {
      "rte": 0.0181,
      "mrpc": 0.0,
      "cola": -0.0077
    },
    "final_avg_accuracy": 0.5948,
    "initial_avg_accuracy": 0.5974
  },
  "time_hours": 0.1233
}